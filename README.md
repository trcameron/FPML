# FPML
FPML: Fourth-order Parallelizable Modified Laguerre method is a collection of Fortran subroutines for computing the roots of a univariate polynomial. All subroutines are located in the module *fpml* inside the src directory.

## Authors
* [Thomas R. Cameron](https://thomasrcameron.com)
    * Mathematics and Computer Science Department, Davidson College
    * [Email: thcameron@davidson.edu](mailto:thcameron@davidson.edu)

## Instructions
Below are instructions for the installation of FPML, the testing of FPML, and compiling of TeX figures. These instructions have been tested on macOS High Sierra 10.13.3 and Ubuntu 16.04.4 LTS and will work on most Mac and Linux systems provided the dependencies are met. 
### Installation
First, open the make.inc file to specify the Fortran compiler and flags. The default settings use the *gfortran* compiler with flags *-O2*. Once these parameters are set, the fpml\_driver and testing library can be installed by running *make install* from the root directory of FPML, in the terminal. Once installed, *make clean* can be run to remove the leftover installation files, such as .mod and .o files. Note that the installation is done relative to the location of the FPML directory and nothing is installed outside of this directory. To uninstall simply run *make uninstall* from the root directory of FPML. 

When running the fpml\_driver, the program will expect the name of a file located in data\_files. This file is expected to store the coefficients of a polynomial as follows: The first row contains the degree, and every subsequent line contains the coefficients from constant to leading (e.g., see poly1.dat). If no data file is given, then the program will run on poly1.dat by default. Each computed root, its backward error, and condition number is recorded in the file results.dat located in data\_files. 
### Run Tests
All tests that were used in the research and development of FPML are included in the tests directory, along with 3rd party software from AMVW [4] and Polzeros [5]. The Fortran 90 software for AMVW is now maintained at https://github.com/eiscor/eiscor, and the Fortran90 software for Polzeros can be downloaded at https://jblevins.org/mirror/amiller/.

Each test can be run individually using the executables inside the tests directory. When running tests that depend on the AMVW eiscor library, Mac users may need to set the DYLD\_LIBRARY\_PATH, see the run\_tests.sh file in the tests directory for the proper export command. Note that the tests init\_est, methods, rand\_poly, and unity take on three parameters: startDegree, endDegree, and itnum. If these parameters are not given, then each test runs on its default setting that is set in its respective source file, located in tests/src. One may also run all tests by running *make run* from the root directory of FPML, the parameters for these test runs may be set from within the make.inc file.

A description of each test and its results are given in Section Tests.
### Compile TeX
After running a test, the results will be in a file (named after the test) located in tests/data\_files. These data files can be viewed as is, or a figure displaying the data can be generated by compiling the associated TeX file (also named after the test) located in tests/TeX. All images can be created and moved into the tests/figures file by running *make compile* from the root directory of FPML.

The compilation of these TeX files requires *pdflatex* and *imagemagick* to first compile the pdf and then convert it to a png. For specific package dependencies see the individual TeX files but note that the typical TeX Live installation should include all necessary packages.
## Tests
The following numerical experiments are provided to motivate our choices in several design aspects of our algorithm, including the use of the monotone chain algorithm and our modification of Laguerre's method. Also, we compare the accuracy and efficiency of our algorithm against AMVW [4] and Polzeros [5]. The results that follow are from tests that were run on an Intel Core i5 CPU running at 2.7 GHz with 16GB of memory.
### Initial Estimate
Below is a graph of the initial estimates and exact roots of the polynomial <img src="https://latex.codecogs.com/svg.latex?\Large&space;p(z)=1+3000z+3000000z^{2}+1000000000z^{3}+z^{10}" title="\Large p(z)=1+3000z+3000000z^{2}+1000000000z^{3}+z^{10}" />.

![alt text](tests/figures/init_est_acc.png?raw=true)

As can be seen from this graph, the initial estimates are incredibly close to the exact roots of the polynomial. While the outcome is not always this favorable, this example highlights the power of the method we use for computing the initial estimates, originally due to Bini [5]. In addition, the plot below compares the divide and conquer method used by Bini and the monotone chain algorithm we employ, originally proposed in [3], for computing the upper envelope of the convex hull needed to compute the initial estimates.

![alt text](tests/figures/init_est_time.png?raw=true)

As expected, the monotone chain algorithm is less expensive than the divide and conquer method for large degree polynomials. 
### Modifications
Random complex polynomials are used to compare several modifications of Laguerre's method and Newton's method. Each polynomial has coefficients with real and imaginary parts uniformly distributed on the interval [-1,1]. The modification of Newton's method was proposed in [1] and is referenced as Aberth's method. The modification we propose is referenced as concurrent Laguerre (Con. Lag.), and the modification used in [10,13] is referenced as sequential Laguerre (Seq. Lag.). The plot below includes the elapsed time measured in seconds and the error measured as the maximum relative forward error (upper bound as the product of the backward error and condition number). Iterations are run for polynomials of degree 80 to degree 10240, doubling the degree on each step. For each iteration there are ten trials performed, we record the average time elapsed and average error over all ten trials.

![alt text](tests/figures/methods.png?raw=true)

As can be seen from the graph above, all three modifications are comparable until the last two degrees tested. In these cases Seq. Lag. is failing to meet the stopping criterion for at least one root approximation, so the maximum backward error and condition number are much higher than the rest. In fact, we've observed that Seq. Lag. requires an increasing number of iterations as the degree of the polynomial grows. This, combined with Seq. Lag. not being parallelizable, is our motivation for using the Con. Lag. modification.
### Convergence
Three special polynomials are used to test the theoretical convergence properties of FPML. The first polynomial is <img src="https://latex.codecogs.com/svg.latex?\Large&space;z^{5}-1" title="\Large z^{5}-1" />, the second is the degree 10 Chebyshev polynomial of the first kind, and the third polynomial is <img src="https://latex.codecogs.com/svg.latex?\Large&space;z^{20}+z^{19}+\cdots+z+1">. We measure the error after each iteration as the maximum relative forward error in our root approximations. The results are recorded in the table below. The column Error-i corresponds to the error in the root approximations for the ith polynomial. 

![alt text](tests/figures/conv.png?raw=true)

Note the evidence of fourth-order convergence, which can be seen in each column. To see this in practice is a somewhat of a surprising feature of our method. Often, higher order methods do not display their convergence rate in practice, as the approximations must be so close to the exact roots before convergence will set in that it will not be noticed in double-precision floating-point arithmetic.
### Random Polynomials
Random complex polynomials are used to compare FPML against Polzeros and the single shift version of AMVW. Each polynomial has coefficients with real and imaginary parts uniformly distributed on the interval [-1,1]. The plot below includes the elapsed time measured in seconds and the error measured as the maximum relative forward error (upper bound as the product of the backward error and condition number). Iterations are run for polynomials of degree 80 to degree 10240, doubling the degree on each step. For each iteration there are ten trials performed, we record the average time elapsed and average error over all ten trials. 

![alt text](tests/figures/rand_poly.png?raw=true)

It is clear from the above figure that FPML and Polzeros are very close concerning speed, with FPML having a slight advantage and AMVW being about two times slower on average. Also, in this test, FPML is on average twice as accurate as both AMVW and Polzeros.
### Roots of Unity
The roots of the polynomial <img src="https://latex.codecogs.com/svg.latex?\Large&space;z^{n}-1" title="\Large z^{n}-1" /> are the n roots of unity: <img src="https://latex.codecogs.com/svg.latex?\Large&space;\cos(\frac{2\pi}{n}j)+i\sin(\frac{2\pi}{n}j)" title="\Large \cos(\frac{2\pi}{n}j)+i\sin(\frac{2\pi}{n}j)" /> for <img src="https://latex.codecogs.com/svg.latex?\Large&space;j=1,\ldots,n" title="\Large j=1,\ldots,n" />. The plot below includes the elapsed time measured in seconds and the error measured as the average absolute difference between the computed and exact roots. Iterations are run for polynomials of degree 80 to degree 10240, doubling the degree on each step. For each iteration there are ten trials performed, we record the average time elapsed and error over all ten trials. 

![alt text](tests/figures/unity.png?raw=true)

It is clear from the figure above that FPML and Polzeros are very close concerning both speed and accuracy; whereas, AMVW is both slower and less accurate in this test. 
### Special Polynomials
Below is a table describing the special polynomials that we use to provide additional comparisons in the accuracy of FPML, Polzeros, and AMVW. Each of these polynomials was used for testing in [4]; originally, polynomials 1--11 were used in [8] and polynomials 12--14 were used in [6].

![alt text](tests/figures/spec_poly_list.png?raw=true)

For each special polynomial, the roots are computed, and the maximum relative forward error is recorded in the table below.

![alt text](tests/figures/spec_poly_results.png?raw=true)

It is clear that FPML and Polzeros have comparable accuracy when solving for the roots of each of the above special polynomials. There are several polynomials where FPML is at least an order of magnitude better than both AMVW and Polzeros (e.g., 1, 2, 5, 10, 13), and only one polynomial where FPML is at least an order of magnitude worse (e.g., 9). Finally, there are several polynomials where the accuracy of AMVW is much worse than FPML and Polzeros (e.g., 3, 5, 6, 8, 12).
## References
Below is a list of references that were used during our research.

1. O. Aberth, *Iteration methods for finding all zeros of a polynomial simultaneously*, Math. Comp. **27** (1973), no. 122, 339-344.
2. F. S. Acton, *Numerical methods that work*, Harper and Row, New York, New York, 1970.
3. A. M. Andrew, *Another efficient algorithm for convex hulls in two dimensions*, Info. Proc. Letters **9** (1979), no. 5, 216-219.
4. J. L. Aurentz, T. Mach, R. Vandebril, and D. S. Watkins, *Fast and backward stable computation of roots of polynomials*, SIAM J. Matrix Anal. Appl. **36** (2015), no. 3, 942-973.
5. D. A. Bini, *Numerical computation of polynomial zeros by means of Aberth's method*, Numer. Algorithms **13** (1996), 179-200
6. D. A. Bini and G. Fiorentino, *Design, analysis, and implementation of a multiprecision polynomial root finder*, Numer. Algorithms **23** (2000), 127-173.
7. D. A. Bini and V. Noferini, *Solving the polynomial eigenvalue problem by means of the Ehrlich-Aberth method*, Linear Algebra Appl. **439** (2013), 1130-1149.
8. S. Chandrasekaran, M. Gu, J. Xia, and J. Zhu, *A fast QR algorithm for companion matrices*, Recent Advances in Matrix and Operator Theory (Basel), Birkhauser Basel, 2008, pp. 111-143. 
9. E. Hansen, M. Patrick, and J. Rusnak, *Some modifications of Laguerre's method*, BIT **17** (1977), no. 4, 409-417.
10. P. Lancaster, *Lambda-matrices and vibrating systems*, International Series of Monographs on Pure and Applied Mathematics, vol. 94, Pergamon, Oxford, United Kingdom, 1966.
11. M. R. Leuze, *A hybrid Laguerre method*, BIT **23** (1983), no. 1, 132-138.
12. A. M. Ostrowski, *Solution of Equations in Euclidean and Banach Spaces*, 3rd ed., Academic Press, New York, New York, 1973. 
13. B. Parlett, *Laguerre's method applied to the matrix eigenvalue problem*, Math. Comp. **18** (1964), no. 87, 464-485.
14. A. E. Pellet, *Sur un mode de separation des racines des equations et la formule de Lagrange*, Bull. Sci. Math. **5** (1881), no. 2, 393-395.
15. M. S. Petkovic, L. Petkovic, and D. Zivkovic *Laguerre-like methods for the simultaneous approximation of polynomial zeros*, Topics in Numerical Analysis (Vienna), Springer Vienna, 2001, pp. 189-209. 
16. K. A. Redish, *On Laguerre's method*, Int J. of Math. Educ. in Sci. and Tech. **5** (1974), no. 1, 91-102.
17. F. Tisseur, *Backward error and condition of polynomial eigenvalue problems*, Linear Algebra Appl. **309** (2000), no. 1-3, 339-361.
18. J. L. Walsh, *On Pellet's theorem concerning the roots of a polynomial*, Ann. of Math. **26** (1924), 59-64.
19. J. H. Wilkinson, *The algebraic eigenvalue problem*, Clarendon Press, Oxford, United Kingdom, 1965. 